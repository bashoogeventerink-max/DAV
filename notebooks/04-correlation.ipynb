{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "beb5677d",
   "metadata": {},
   "source": [
    "First test in notebook for correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5bdd7611",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from loguru import logger\n",
    "import warnings\n",
    "from textblob import TextBlob\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d86c2fff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>message</th>\n",
       "      <th>living_in_city</th>\n",
       "      <th>tech_background</th>\n",
       "      <th>author</th>\n",
       "      <th>has_emoji</th>\n",
       "      <th>word_count</th>\n",
       "      <th>react_time_sec</th>\n",
       "      <th>react_time_min</th>\n",
       "      <th>react_time_hr</th>\n",
       "      <th>is_image</th>\n",
       "      <th>is_empty_message</th>\n",
       "      <th>is_removed_message</th>\n",
       "      <th>sentiment_polarity</th>\n",
       "      <th>sentiment_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-09-16 07:31:00+00:00</td>\n",
       "      <td>Wachten op dit bericht</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>spattered-duck</td>\n",
       "      <td>False</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-09-16 07:41:00+00:00</td>\n",
       "      <td>Wachten op dit bericht</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>riotous-dingo</td>\n",
       "      <td>False</td>\n",
       "      <td>4.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-09-16 08:21:00+00:00</td>\n",
       "      <td>Wachten op dit bericht</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>translucent-dog</td>\n",
       "      <td>False</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-09-16 08:23:00+00:00</td>\n",
       "      <td>Wachten op dit bericht</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>hypnotic-rabbit</td>\n",
       "      <td>False</td>\n",
       "      <td>4.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-09-16 09:08:00+00:00</td>\n",
       "      <td>Wachten op dit bericht</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>crystalline-uakari</td>\n",
       "      <td>False</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2700.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  timestamp                 message  living_in_city  \\\n",
       "0 2022-09-16 07:31:00+00:00  Wachten op dit bericht               1   \n",
       "1 2022-09-16 07:41:00+00:00  Wachten op dit bericht               0   \n",
       "2 2022-09-16 08:21:00+00:00  Wachten op dit bericht               0   \n",
       "3 2022-09-16 08:23:00+00:00  Wachten op dit bericht               0   \n",
       "4 2022-09-16 09:08:00+00:00  Wachten op dit bericht               0   \n",
       "\n",
       "   tech_background              author  has_emoji  word_count  react_time_sec  \\\n",
       "0                1      spattered-duck      False         4.0             NaN   \n",
       "1                1       riotous-dingo      False         4.0           600.0   \n",
       "2                0     translucent-dog      False         4.0          2400.0   \n",
       "3                0     hypnotic-rabbit      False         4.0           120.0   \n",
       "4                1  crystalline-uakari      False         4.0          2700.0   \n",
       "\n",
       "   react_time_min  react_time_hr  is_image  is_empty_message  \\\n",
       "0             NaN            NaN         0                 1   \n",
       "1            10.0       0.166667         0                 1   \n",
       "2            40.0       0.666667         0                 1   \n",
       "3             2.0       0.033333         0                 1   \n",
       "4            45.0       0.750000         0                 1   \n",
       "\n",
       "   is_removed_message  sentiment_polarity sentiment_category  \n",
       "0                   0                 0.0            Neutral  \n",
       "1                   0                 0.0            Neutral  \n",
       "2                   0                 0.0            Neutral  \n",
       "3                   0                 0.0            Neutral  \n",
       "4                   0                 0.0            Neutral  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tomllib\n",
    "\n",
    "configfile = Path(\"../config.toml\").resolve()\n",
    "with configfile.open(\"rb\") as f:\n",
    "    config = tomllib.load(f)\n",
    "datafile = (Path(\"..\") / Path(config[\"processed\"]) / config[\"current\"]).resolve()\n",
    "if not datafile.exists():\n",
    "    logger.warning(\n",
    "        \"Datafile does not exist. First run src/preprocess.py, and check the timestamp!\"\n",
    "    )\n",
    "df = pd.read_parquet(datafile)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5529ad",
   "metadata": {},
   "source": [
    "options:\n",
    "- word_count and has_emoji (maybe a negative correlation)\n",
    "- word_count and react_time (short messages can be responded quicker) - Straight forward\n",
    "- react_time and user activity (negative correlation)\n",
    "- Sentiment between users"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a786439a",
   "metadata": {},
   "source": [
    "Sentiment correlation between users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf59bacb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment_category  Positive  Neutral  Negative  Total Messages\n",
      "author                                                         \n",
      "giggly-xenops            112     1061        22            1195\n",
      "goofy-chimpanzee         130     1027        25            1182\n",
      "goofy-wombat              68     1219        13            1300\n",
      "hilarious-human           75      745        17             837\n",
      "jubilant-goshawk         190     1406        31            1627\n",
      "quirky-pony              130      914        18            1062\n",
      "radiant-bee              128     1100        53            1281\n",
      "rubbery-butterfly         91     1028        31            1150\n",
      "whimsical-gorilla         33      459         9             501\n"
     ]
    }
   ],
   "source": [
    "# Group by author\n",
    "sentiment_counts = df.groupby(['author', 'sentiment_category']).size().unstack(fill_value=0)\n",
    "\n",
    "# add total messages\n",
    "sentiment_counts['Total Messages'] = sentiment_counts.sum(axis=1)\n",
    "\n",
    "# apply order\n",
    "sentiment_order = ['Positive', 'Neutral', 'Negative', 'Total Messages']\n",
    "\n",
    "result_df = sentiment_counts.reindex(columns=sentiment_order, fill_value=0)\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468c850b",
   "metadata": {},
   "source": [
    "Not really useful insights from sentiment. Let's see other correlations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "abc71990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  author sentiment_category  \\\n",
      "10           quirky-pony           Negative   \n",
      "54      goofy-chimpanzee           Negative   \n",
      "141          quirky-pony           Negative   \n",
      "348    rubbery-butterfly           Negative   \n",
      "405      hilarious-human           Negative   \n",
      "...                  ...                ...   \n",
      "9856        goofy-wombat           Negative   \n",
      "9953         radiant-bee           Negative   \n",
      "9954        goofy-wombat           Negative   \n",
      "10083   jubilant-goshawk           Negative   \n",
      "10125  rubbery-butterfly           Negative   \n",
      "\n",
      "                                                 message  \n",
      "10                  Sorry man ik heb feestje van familie  \n",
      "54                                         Nee man sorry  \n",
      "141        Hoe the fuck krijg je brobbey tegen de vlakte  \n",
      "348           Tegen half 9 - 9 uur zou ik nog wel kunnen  \n",
      "405                                      Half 9 is prima  \n",
      "...                                                  ...  \n",
      "9856                     Ik ben dan niet in Nederland :(  \n",
      "9953            Ik ben dat weekend niet in Twente man :/  \n",
      "9954                                                 Sad  \n",
      "10083  Ja heb dus op m'n kamer een Mickey Mouse doos ...  \n",
      "10125                      8 uur koffie, half 9 beginnen  \n",
      "\n",
      "[219 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Use boolean indexing to filter the DataFrame\n",
    "negative_messages = df[df['sentiment_category'] == 'Negative']\n",
    "\n",
    "# Print the author, sentiment category, and the actual message\n",
    "print(negative_messages[['author', 'sentiment_category', 'message']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f423143",
   "metadata": {},
   "source": [
    "Word count per user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "370589e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               Min Word Count  Median Word Count  \\\n",
      "author                                                             \n",
      "carbonated-red-eyed tree frog             1.0                5.0   \n",
      "chuckling-ibis                            1.0                4.0   \n",
      "eye-catching-pelican                      1.0                4.0   \n",
      "frothy-barracuda                          1.0                5.0   \n",
      "hypnotic-stinkbug                         1.0                3.0   \n",
      "piebald-coyote                            1.0                5.0   \n",
      "roguish-shark                             1.0                5.0   \n",
      "silky-jellyfish                           1.0                4.0   \n",
      "whimsical-human                           1.0                5.0   \n",
      "\n",
      "                               Average Word Count  Max Word Count  \n",
      "author                                                             \n",
      "carbonated-red-eyed tree frog            6.688172           161.0  \n",
      "chuckling-ibis                           5.426957            77.0  \n",
      "eye-catching-pelican                     5.171875           107.0  \n",
      "frothy-barracuda                         7.535341           238.0  \n",
      "hypnotic-stinkbug                        5.971473            95.0  \n",
      "piebald-coyote                           8.001996           205.0  \n",
      "roguish-shark                            7.721943            83.0  \n",
      "silky-jellyfish                          4.669180            56.0  \n",
      "whimsical-human                          5.928027            71.0  \n"
     ]
    }
   ],
   "source": [
    "word_count_stats = df.groupby('author')['word_count'].agg(\n",
    "    [('Min Word Count', 'min'), \n",
    "     ('Median Word Count', 'median'), \n",
    "     ('Average Word Count', 'mean'), \n",
    "     ('Max Word Count', 'max')]\n",
    ")\n",
    "\n",
    "print(word_count_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e348474",
   "metadata": {},
   "source": [
    "split into group of tech and non-technical backbround"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a1eab230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Min Word Count  Median Word Count  Average Word Count  \\\n",
      "tech_background                                                          \n",
      "0                           1.0                5.0            6.932708   \n",
      "1                           1.0                4.0            5.531656   \n",
      "\n",
      "                 Max Word Count  \n",
      "tech_background                  \n",
      "0                         238.0  \n",
      "1                          95.0  \n"
     ]
    }
   ],
   "source": [
    "tech_word_count_stats = df.groupby('tech_background')['word_count'].agg(\n",
    "    [('Min Word Count', 'min'), \n",
    "     ('Median Word Count', 'median'), \n",
    "     ('Average Word Count', 'mean'), \n",
    "     ('Max Word Count', 'max')]\n",
    ")\n",
    "\n",
    "print(tech_word_count_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d201544d",
   "metadata": {},
   "source": [
    "Calculate the correlation between two attributes. Check data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "00923520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int64\n",
      "float64\n"
     ]
    }
   ],
   "source": [
    "print(df['tech_background'].dtype)\n",
    "print(df['word_count'].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "68e36ad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Point-Biserial Correlation: nan\n",
      "P-value: nan\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "# Assuming your DataFrame is named 'df'\n",
    "correlation, p_value = stats.pointbiserialr(df['tech_background'], df['word_count'])\n",
    "\n",
    "print(f\"Point-Biserial Correlation: {correlation:.4f}\")\n",
    "print(f\"P-value: {p_value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7436398",
   "metadata": {},
   "source": [
    "Test if variance might be 0 so correlation cannot be calculated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d6f616fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard deviation of 'technical_background': 0.498668555488144\n",
      "Standard deviation of 'word_count': 8.195553198526575\n"
     ]
    }
   ],
   "source": [
    "print(f\"Standard deviation of 'technical_background': {df['tech_background'].std()}\")\n",
    "print(f\"Standard deviation of 'word_count': {df['word_count'].std()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f7702b",
   "metadata": {},
   "source": [
    "Check for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5f193837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in 'technical_background': 0\n",
      "Missing values in 'word_count': 6\n"
     ]
    }
   ],
   "source": [
    "print(f\"Missing values in 'technical_background': {df['tech_background'].isnull().sum()}\")\n",
    "print(f\"Missing values in 'word_count': {df['word_count'].isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4d6f3352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Point-Biserial Correlation: -0.0852\n",
      "P-value: 0.0000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "\n",
    "# Assuming 'df' is your DataFrame\n",
    "# First, ensure your columns have the correct data types.\n",
    "# This step is crucial if the columns are of 'object' or other non-numeric types.\n",
    "df['tech_background'] = df['tech_background'].astype(int)\n",
    "df['word_count'] = pd.to_numeric(df['word_count'], errors='coerce')\n",
    "\n",
    "# Drop the records (rows) where 'word_count' is NaN\n",
    "df_cleaned = df.dropna(subset=['word_count'])\n",
    "\n",
    "# Now, calculate the Point-Biserial Correlation on the cleaned DataFrame\n",
    "correlation, p_value = stats.pointbiserialr(df_cleaned['tech_background'], df_cleaned['word_count'])\n",
    "\n",
    "print(f\"Point-Biserial Correlation: {correlation:.4f}\")\n",
    "print(f\"P-value: {p_value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "505d910e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Point-Biserial Correlation: -0.0827\n",
      "P-value: 0.0000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "\n",
    "# Assuming 'df' is your DataFrame\n",
    "# First, ensure your columns have the correct data types.\n",
    "# This step is crucial if the columns are of 'object' or other non-numeric types.\n",
    "df['tech_background'] = df['tech_background'].astype(int)\n",
    "df['word_count'] = pd.to_numeric(df['word_count'], errors='coerce')\n",
    "\n",
    "# Drop the records (rows) where 'word_count' is NaN\n",
    "df_cleaned = df.dropna(subset=['word_count'])\n",
    "\n",
    "# Filter the DataFrame in a single step using boolean indexing\n",
    "df_filtered = df_cleaned[\n",
    "    (df_cleaned['is_image'] == 0) &\n",
    "    (df_cleaned['is_empty_message'] == 0) &\n",
    "    (df_cleaned['is_removed_message'] == 0)\n",
    "]\n",
    "\n",
    "# Now, calculate the Point-Biserial Correlation on the cleaned DataFrame\n",
    "correlation, p_value = stats.pointbiserialr(df_filtered['tech_background'], df_filtered['word_count'])\n",
    "\n",
    "print(f\"Point-Biserial Correlation: {correlation:.4f}\")\n",
    "print(f\"P-value: {p_value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b04a53",
   "metadata": {},
   "source": [
    "Correlation between words count and react_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "31b79e23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n",
      "float64\n"
     ]
    }
   ],
   "source": [
    "print(df['react_time_min'].dtype)\n",
    "print(df['word_count'].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1a68c4e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN counts per column:\n",
      "timestamp             0\n",
      "message               6\n",
      "living_in_city        0\n",
      "tech_background       0\n",
      "author                0\n",
      "has_emoji             0\n",
      "word_count            6\n",
      "react_time_sec        1\n",
      "react_time_min        1\n",
      "react_time_hr         1\n",
      "is_image              0\n",
      "is_empty_message      0\n",
      "is_removed_message    0\n",
      "sentiment_polarity    0\n",
      "sentiment_category    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count NaN values in all columns\n",
    "nan_counts = df.isnull().sum()\n",
    "print(\"NaN counts per column:\")\n",
    "print(nan_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4ed159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Pearson correlation coefficient is: nan\n",
      "The p-value is: nan\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "# Drop the records (rows) where 'word_count' is NaN\n",
    "df_cleaned = df.dropna(subset=['word_count', 'react_time_min'])\n",
    "\n",
    "\n",
    "# Calculate correlation coefficient and p-value\n",
    "correlation, p_value = pearsonr(df_cleaned['word_count'], df_cleaned['react_time_min'])\n",
    "\n",
    "print(f\"The Pearson correlation coefficient is: {correlation:.2f}\")\n",
    "print(f\"The p-value is: {p_value:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dav",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
